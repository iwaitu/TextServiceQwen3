# Qwen3 gRPC Service Docker éƒ¨ç½²æŒ‡å—

æœ¬é¡¹ç›®æä¾›äº†åŸºäº NVIDIA CUDA çš„ Docker å®¹å™¨åŒ–æ–¹æ¡ˆï¼Œæ”¯æŒ GPU åŠ é€Ÿçš„ Qwen3 æ–‡æœ¬åµŒå…¥å’Œé‡æ’åºæœåŠ¡ã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

### 1. NVIDIA Docker è¿è¡Œæ—¶
ç¡®ä¿æ‚¨çš„ç³»ç»Ÿå·²å®‰è£…ï¼š
- NVIDIA GPU é©±åŠ¨ç¨‹åº
- Docker
- NVIDIA Container Toolkit

### 2. å®‰è£… NVIDIA Container Toolkit
```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### 3. éªŒè¯ GPU æ”¯æŒ
```bash
docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1ï¼šä½¿ç”¨æ„å»ºè„šæœ¬ï¼ˆæ¨èï¼‰
```bash
# Windows
build-docker.bat

# Linux/Mac
chmod +x build-docker.sh
./build-docker.sh
```

### æ–¹å¼2ï¼šä½¿ç”¨ docker-compose
```bash
docker-compose up -d
```

### æ–¹å¼3ï¼šæ‰‹åŠ¨æ„å»ºå’Œè¿è¡Œ
```bash
# æ„å»ºé•œåƒ
docker build -t qwen3-grpc-service:latest .

# è¿è¡Œå®¹å™¨ï¼ˆGPUæ”¯æŒï¼‰
docker run -d \
  -p 32688:32688 \
  --gpus all \
  --name qwen3-grpc \
  -v $(pwd)/Models:/app/Models:ro \
  qwen3-grpc-service:latest
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡
- `GRPC_PORT`: gRPCæœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š32688ï¼‰
- `CUDA_VISIBLE_DEVICES`: æŒ‡å®šä½¿ç”¨çš„GPUï¼ˆé»˜è®¤ï¼š0ï¼‰

### ç«¯å£æ˜ å°„
- å®¹å™¨ç«¯å£ï¼š32688
- ä¸»æœºç«¯å£ï¼š32688

### æ¨¡å‹æ–‡ä»¶
æ¨¡å‹æ–‡ä»¶åº”æ”¾åœ¨ `./Models/` ç›®å½•ä¸‹ï¼š
```
Models/
â”œâ”€â”€ Qwen3-Embedding-0.6B/
â””â”€â”€ Qwen3-Reranker-0.6B/
```

## ğŸ” å¥åº·æ£€æŸ¥

å®¹å™¨å¯åŠ¨åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼š

```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker ps

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs qwen3-grpc

# æµ‹è¯•gRPCè¿æ¥
python -c "import grpc; channel = grpc.insecure_channel('localhost:32688'); print('è¿æ¥æˆåŠŸ'); channel.close()"
```

## ğŸ› æ•…éšœæ’é™¤

### 1. GPU ä¸å¯ç”¨
```bash
# æ£€æŸ¥NVIDIAé©±åŠ¨
nvidia-smi

# æ£€æŸ¥Docker GPUæ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi
```

### 2. å†…å­˜ä¸è¶³
- è°ƒæ•´ docker-compose.yml ä¸­çš„å†…å­˜é™åˆ¶
- ç¡®ä¿ä¸»æœºæœ‰è¶³å¤Ÿçš„GPUå†…å­˜

### 3. æ¨¡å‹åŠ è½½å¤±è´¥
- æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„
- ç¡®ä¿æ¨¡å‹æ–‡ä»¶å®Œæ•´ä¸”å¯è¯»

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### GPU å†…å­˜ä¼˜åŒ–
- è®¾ç½®é€‚å½“çš„ `CUDA_VISIBLE_DEVICES`
- è°ƒæ•´æ‰¹å¤„ç†å¤§å°
- å¯ç”¨æ¨¡å‹é‡åŒ–ï¼ˆå¦‚é€‚ç”¨ï¼‰

### å®¹å™¨èµ„æºé™åˆ¶
åœ¨ docker-compose.yml ä¸­è°ƒæ•´ï¼š
```yaml
deploy:
  resources:
    limits:
      memory: 16G  # æ ¹æ®éœ€è¦è°ƒæ•´
    reservations:
      memory: 8G
```

## ğŸ“ API ä½¿ç”¨ç¤ºä¾‹

æœåŠ¡å¯åŠ¨åï¼Œå¯é€šè¿‡ gRPC å®¢æˆ·ç«¯è°ƒç”¨ä»¥ä¸‹æœåŠ¡ï¼š
- `EmbedText`: æ–‡æœ¬åµŒå…¥
- `SimpleRerank`: æ–‡æ¡£é‡æ’åº
- `SplitTextIntoChunks`: æ–‡æœ¬åˆ†å—
- `HealthCheck`: å¥åº·æ£€æŸ¥
- `GetModelInfo`: æ¨¡å‹ä¿¡æ¯

ç«¯å£ï¼š`localhost:32688`
